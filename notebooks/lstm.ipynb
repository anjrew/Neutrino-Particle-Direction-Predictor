{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Neutrino Direction with an LSTM\n",
    "\n",
    "Using a Tensorflow LSTM layer using the event time steps to the input to predict the Neutrino Direction azimuth and zenith angle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "from sys import getsizeof\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Typing imports\n",
    "from typing import List, Tuple\n",
    "\n",
    "from scripts.utils import seed_it_all, compose_event_df, reduce_mem_usage, convert_bytes_to_gmbkb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IS_TRAINING = True # Whether to train the model\n",
    "SEED=10\n",
    "\n",
    "TIME_LIMIT_HOURS = 1\n",
    "\n",
    "PULSE_AMOUNT = 100 # Amount of pulses to use for features\n",
    "FEATURES = [ 'time', 'charge', 'auxiliary', 'x', 'y', 'z'] # Which features to use as the model input\n",
    "\n",
    "# Directories\n",
    "DATA_DIR = \"../data\"\n",
    "SET = 'train' if IS_TRAINING else 'test'\n",
    "\n",
    "# logging\n",
    "LOG_LEVEL = logging.INFO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(filename='artifacts/info.log', level=LOG_LEVEL, format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_it_all(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_dtypes = { 'x': 'float16', 'y': 'float16', 'z': 'float16' }\n",
    "sensor_geometry_df = pd.read_csv(f'{DATA_DIR}/sensor_geometry.csv', dtype=sensor_dtypes)\n",
    "sensor_geometry_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_bytes_to_gmbkb(getsizeof(sensor_geometry_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta_dtypes = {'batch_id': 'int16', 'event_id': 'Int64', 'first_pulse_index': 'int32', 'last_pulse_index': 'int32', 'azimuth': 'float16', 'zenith': 'float16'}\n",
    "meta_df = pd.read_parquet(f'{DATA_DIR}/{SET}_meta.parquet').astype(meta_dtypes)\n",
    "meta_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_bytes_to_gmbkb(getsizeof(meta_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_directory = f'{DATA_DIR}/{SET}'\n",
    "batch_file_paths = [f'{batch_directory}/{file}' for file in os.listdir(batch_directory) if os.path.isfile(os.path.join(batch_directory, file))]\n",
    "print('First batch file path 3 Samples:')\n",
    "batch_file_paths[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch_df= pd.read_parquet(batch_file_paths[1])\n",
    "convert_bytes_to_gmbkb(getsizeof(meta_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a generator function\n",
    "def data_generator(\n",
    "    batch_paths:List[str],\n",
    "    sensor_geometry:pd.DataFrame,\n",
    "    meta_data: pd.DataFrame, \n",
    "    sequence_length:int,\n",
    "    batch_size:int=32\n",
    "):\n",
    "    \"\"\"Emits a single event training example to be called by the model.fit_generator() method.\n",
    "\n",
    "    Args:\n",
    "        batch_paths (List[str]): A list of paths to the batch files\n",
    "        sensor_geometry_df (pd.DataFrame): The sensor geometry dataframe\n",
    "        meta_df (pd.DataFrame): The dataframe containing the meta data\n",
    "        sequence_length (int): The length of the pulse sequence to use for training\n",
    "\n",
    "    Yields:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    batch_dtypes = {'event_id': 'int32', 'sensor_id': 'int16', 'time': 'int32', 'charge': 'float16', 'auxiliary': 'int8'}\n",
    "    \n",
    "   \n",
    "                \n",
    "    for batch_path in batch_paths:\n",
    "        \n",
    "        batch = pd.read_parquet(batch_path).reset_index().astype(batch_dtypes)\n",
    "        \n",
    "        output_batch = None\n",
    "        \n",
    "        for event_id in batch['event_id'].unique():\n",
    "            \n",
    "            # The event dataframe with a list of pulse readings\n",
    "            event_data = batch[batch['event_id'] == event_id]\n",
    "            \n",
    "            merged_df = pd.merge(event_data, sensor_geometry, on='sensor_id', how='left')\n",
    "            \n",
    "            # get the first N pulses with N being the sequence length\n",
    "            sequence = merged_df.head(sequence_length)[FEATURES]\n",
    "            n_missing = 100 - len(sequence)\n",
    "            if n_missing > 0:\n",
    "                df_missing = pd.DataFrame(0, index=np.arange(n_missing), columns=sequence.columns)\n",
    "                sequence = pd.concat([sequence, df_missing])\n",
    "            \n",
    "            # get the target labels \n",
    "            target_labels = meta_data[meta_data['event_id'] == event_id][['azimuth', 'zenith']].values[0] \n",
    "            \n",
    "            # reshape the sequence and target labels to be fed into the model\n",
    "            x_batch, y_batch = np.reshape(sequence, (sequence_length, len(FEATURES))), np.reshape(target_labels, (1, 2))\n",
    "            \n",
    "            \n",
    "            if output_batch is None:\n",
    "                    output_batch = [[x_batch, y_batch]]\n",
    "                    print('output_batch initializing', len(output_batch))  \n",
    "            else:\n",
    "                if len(output_batch) == batch_size:\n",
    "                    output = np.array(output_batch)\n",
    "                    output_batch = None\n",
    "                    print('output_batch', len(output_batch))  \n",
    "                    print('output', len(output_batch))  \n",
    "                    yield output\n",
    "                else:\n",
    "                    output_batch.extend([x_batch, y_batch])\n",
    "                    print('output_batch extending', len(output_batch),batch_size )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a generator object\n",
    "data_gen = data_generator(batch_file_paths, sensor_geometry_df, meta_df, sequence_length=PULSE_AMOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_batch initializing 1\n",
      "output_batch extending 3\n",
      "output_batch extending 5\n",
      "output_batch extending 7\n",
      "output_batch extending 9\n",
      "output_batch extending 11\n",
      "output_batch extending 13\n",
      "output_batch extending 15\n",
      "output_batch extending 17\n",
      "output_batch extending 19\n",
      "output_batch extending 21\n",
      "output_batch extending 23\n",
      "output_batch extending 25\n",
      "output_batch extending 27\n",
      "output_batch extending 29\n",
      "output_batch extending 31\n",
      "output_batch extending 33\n",
      "output_batch extending 35\n",
      "output_batch extending 37\n",
      "output_batch extending 39\n",
      "output_batch extending 41\n",
      "output_batch extending 43\n",
      "output_batch extending 45\n",
      "output_batch extending 47\n",
      "output_batch extending 49\n",
      "output_batch extending 51\n",
      "output_batch extending 53\n",
      "output_batch extending 55\n",
      "output_batch extending 57\n",
      "output_batch extending 59\n",
      "output_batch extending 61\n",
      "output_batch extending 63\n",
      "output_batch extending 65\n",
      "output_batch extending 67\n",
      "output_batch extending 69\n",
      "output_batch extending 71\n",
      "output_batch extending 73\n",
      "output_batch extending 75\n",
      "output_batch extending 77\n",
      "output_batch extending 79\n",
      "output_batch extending 81\n",
      "output_batch extending 83\n",
      "output_batch extending 85\n",
      "output_batch extending 87\n",
      "output_batch extending 89\n",
      "output_batch extending 91\n",
      "output_batch extending 93\n",
      "output_batch extending 95\n",
      "output_batch extending 97\n",
      "output_batch extending 99\n",
      "output_batch extending 101\n",
      "output_batch extending 103\n",
      "output_batch extending 105\n",
      "output_batch extending 107\n",
      "output_batch extending 109\n",
      "output_batch extending 111\n",
      "output_batch extending 113\n",
      "output_batch extending 115\n",
      "output_batch extending 117\n",
      "output_batch extending 119\n",
      "output_batch extending 121\n",
      "output_batch extending 123\n",
      "output_batch extending 125\n",
      "output_batch extending 127\n",
      "output_batch extending 129\n",
      "output_batch extending 131\n",
      "output_batch extending 133\n",
      "output_batch extending 135\n",
      "output_batch extending 137\n",
      "output_batch extending 139\n",
      "output_batch extending 141\n",
      "output_batch extending 143\n",
      "output_batch extending 145\n",
      "output_batch extending 147\n",
      "output_batch extending 149\n",
      "output_batch extending 151\n",
      "output_batch extending 153\n",
      "output_batch extending 155\n",
      "output_batch extending 157\n",
      "output_batch extending 159\n",
      "output_batch extending 161\n",
      "output_batch extending 163\n",
      "output_batch extending 165\n",
      "output_batch extending 167\n",
      "output_batch extending 169\n",
      "output_batch extending 171\n",
      "output_batch extending 173\n",
      "output_batch extending 175\n",
      "output_batch extending 177\n",
      "output_batch extending 179\n",
      "output_batch extending 181\n",
      "output_batch extending 183\n",
      "output_batch extending 185\n",
      "output_batch extending 187\n",
      "output_batch extending 189\n",
      "output_batch extending 191\n",
      "output_batch extending 193\n",
      "output_batch extending 195\n",
      "output_batch extending 197\n",
      "output_batch extending 199\n",
      "output_batch extending 201\n",
      "output_batch extending 203\n",
      "output_batch extending 205\n",
      "output_batch extending 207\n",
      "output_batch extending 209\n",
      "output_batch extending 211\n",
      "output_batch extending 213\n",
      "output_batch extending 215\n",
      "output_batch extending 217\n",
      "output_batch extending 219\n",
      "output_batch extending 221\n",
      "output_batch extending 223\n",
      "output_batch extending 225\n",
      "output_batch extending 227\n",
      "output_batch extending 229\n",
      "output_batch extending 231\n",
      "output_batch extending 233\n",
      "output_batch extending 235\n",
      "output_batch extending 237\n",
      "output_batch extending 239\n",
      "output_batch extending 241\n",
      "output_batch extending 243\n",
      "output_batch extending 245\n",
      "output_batch extending 247\n",
      "output_batch extending 249\n",
      "output_batch extending 251\n",
      "output_batch extending 253\n",
      "output_batch extending 255\n",
      "output_batch extending 257\n",
      "output_batch extending 259\n",
      "output_batch extending 261\n",
      "output_batch extending 263\n",
      "output_batch extending 265\n",
      "output_batch extending 267\n",
      "output_batch extending 269\n",
      "output_batch extending 271\n",
      "output_batch extending 273\n",
      "output_batch extending 275\n",
      "output_batch extending 277\n",
      "output_batch extending 279\n",
      "output_batch extending 281\n",
      "output_batch extending 283\n",
      "output_batch extending 285\n",
      "output_batch extending 287\n",
      "output_batch extending 289\n",
      "output_batch extending 291\n",
      "output_batch extending 293\n",
      "output_batch extending 295\n",
      "output_batch extending 297\n",
      "output_batch extending 299\n",
      "output_batch extending 301\n",
      "output_batch extending 303\n",
      "output_batch extending 305\n",
      "output_batch extending 307\n",
      "output_batch extending 309\n",
      "output_batch extending 311\n",
      "output_batch extending 313\n",
      "output_batch extending 315\n",
      "output_batch extending 317\n",
      "output_batch extending 319\n",
      "output_batch extending 321\n",
      "output_batch extending 323\n",
      "output_batch extending 325\n",
      "output_batch extending 327\n",
      "output_batch extending 329\n",
      "output_batch extending 331\n",
      "output_batch extending 333\n",
      "output_batch extending 335\n",
      "output_batch extending 337\n",
      "output_batch extending 339\n",
      "output_batch extending 341\n",
      "output_batch extending 343\n",
      "output_batch extending 345\n",
      "output_batch extending 347\n",
      "output_batch extending 349\n",
      "output_batch extending 351\n",
      "output_batch extending 353\n",
      "output_batch extending 355\n",
      "output_batch extending 357\n",
      "output_batch extending 359\n",
      "output_batch extending 361\n",
      "output_batch extending 363\n",
      "output_batch extending 365\n",
      "output_batch extending 367\n",
      "output_batch extending 369\n",
      "output_batch extending 371\n",
      "output_batch extending 373\n",
      "output_batch extending 375\n",
      "output_batch extending 377\n",
      "output_batch extending 379\n",
      "output_batch extending 381\n",
      "output_batch extending 383\n",
      "output_batch extending 385\n",
      "output_batch extending 387\n",
      "output_batch extending 389\n",
      "output_batch extending 391\n",
      "output_batch extending 393\n",
      "output_batch extending 395\n",
      "output_batch extending 397\n",
      "output_batch extending 399\n",
      "output_batch extending 401\n",
      "output_batch extending 403\n",
      "output_batch extending 405\n",
      "output_batch extending 407\n",
      "output_batch extending 409\n",
      "output_batch extending 411\n",
      "output_batch extending 413\n",
      "output_batch extending 415\n",
      "output_batch extending 417\n",
      "output_batch extending 419\n",
      "output_batch extending 421\n",
      "output_batch extending 423\n",
      "output_batch extending 425\n",
      "output_batch extending 427\n",
      "output_batch extending 429\n",
      "output_batch extending 431\n",
      "output_batch extending 433\n",
      "output_batch extending 435\n",
      "output_batch extending 437\n",
      "output_batch extending 439\n",
      "output_batch extending 441\n",
      "output_batch extending 443\n",
      "output_batch extending 445\n",
      "output_batch extending 447\n",
      "output_batch extending 449\n",
      "output_batch extending 451\n",
      "output_batch extending 453\n",
      "output_batch extending 455\n",
      "output_batch extending 457\n",
      "output_batch extending 459\n",
      "output_batch extending 461\n",
      "output_batch extending 463\n",
      "output_batch extending 465\n",
      "output_batch extending 467\n",
      "output_batch extending 469\n",
      "output_batch extending 471\n",
      "output_batch extending 473\n",
      "output_batch extending 475\n",
      "output_batch extending 477\n",
      "output_batch extending 479\n",
      "output_batch extending 481\n",
      "output_batch extending 483\n",
      "output_batch extending 485\n",
      "output_batch extending 487\n",
      "output_batch extending 489\n",
      "output_batch extending 491\n",
      "output_batch extending 493\n",
      "output_batch extending 495\n",
      "output_batch extending 497\n",
      "output_batch extending 499\n",
      "output_batch extending 501\n",
      "output_batch extending 503\n",
      "output_batch extending 505\n",
      "output_batch extending 507\n",
      "output_batch extending 509\n",
      "output_batch extending 511\n",
      "output_batch extending 513\n",
      "output_batch extending 515\n",
      "output_batch extending 517\n",
      "output_batch extending 519\n",
      "output_batch extending 521\n",
      "output_batch extending 523\n",
      "output_batch extending 525\n",
      "output_batch extending 527\n",
      "output_batch extending 529\n",
      "output_batch extending 531\n",
      "output_batch extending 533\n",
      "output_batch extending 535\n",
      "output_batch extending 537\n",
      "output_batch extending 539\n",
      "output_batch extending 541\n",
      "output_batch extending 543\n",
      "output_batch extending 545\n",
      "output_batch extending 547\n",
      "output_batch extending 549\n",
      "output_batch extending 551\n",
      "output_batch extending 553\n",
      "output_batch extending 555\n",
      "output_batch extending 557\n",
      "output_batch extending 559\n",
      "output_batch extending 561\n",
      "output_batch extending 563\n",
      "output_batch extending 565\n",
      "output_batch extending 567\n",
      "output_batch extending 569\n",
      "output_batch extending 571\n",
      "output_batch extending 573\n",
      "output_batch extending 575\n",
      "output_batch extending 577\n",
      "output_batch extending 579\n",
      "output_batch extending 581\n",
      "output_batch extending 583\n",
      "output_batch extending 585\n",
      "output_batch extending 587\n",
      "output_batch extending 589\n",
      "output_batch extending 591\n",
      "output_batch extending 593\n",
      "output_batch extending 595\n",
      "output_batch extending 597\n",
      "output_batch extending 599\n",
      "output_batch extending 601\n",
      "output_batch extending 603\n",
      "output_batch extending 605\n",
      "output_batch extending 607\n",
      "output_batch extending 609\n",
      "output_batch extending 611\n",
      "output_batch extending 613\n",
      "output_batch extending 615\n",
      "output_batch extending 617\n",
      "output_batch extending 619\n",
      "output_batch extending 621\n",
      "output_batch extending 623\n",
      "output_batch extending 625\n",
      "output_batch extending 627\n",
      "output_batch extending 629\n",
      "output_batch extending 631\n",
      "output_batch extending 633\n",
      "output_batch extending 635\n",
      "output_batch extending 637\n",
      "output_batch extending 639\n",
      "output_batch extending 641\n",
      "output_batch extending 643\n",
      "output_batch extending 645\n",
      "output_batch extending 647\n",
      "output_batch extending 649\n",
      "output_batch extending 651\n",
      "output_batch extending 653\n",
      "output_batch extending 655\n",
      "output_batch extending 657\n",
      "output_batch extending 659\n",
      "output_batch extending 661\n",
      "output_batch extending 663\n",
      "output_batch extending 665\n",
      "output_batch extending 667\n",
      "output_batch extending 669\n",
      "output_batch extending 671\n",
      "output_batch extending 673\n",
      "output_batch extending 675\n",
      "output_batch extending 677\n",
      "output_batch extending 679\n",
      "output_batch extending 681\n",
      "output_batch extending 683\n",
      "output_batch extending 685\n",
      "output_batch extending 687\n",
      "output_batch extending 689\n",
      "output_batch extending 691\n",
      "output_batch extending 693\n",
      "output_batch extending 695\n",
      "output_batch extending 697\n",
      "output_batch extending 699\n",
      "output_batch extending 701\n",
      "output_batch extending 703\n",
      "output_batch extending 705\n",
      "output_batch extending 707\n",
      "output_batch extending 709\n",
      "output_batch extending 711\n",
      "output_batch extending 713\n",
      "output_batch extending 715\n",
      "output_batch extending 717\n",
      "output_batch extending 719\n",
      "output_batch extending 721\n",
      "output_batch extending 723\n",
      "output_batch extending 725\n",
      "output_batch extending 727\n",
      "output_batch extending 729\n",
      "output_batch extending 731\n",
      "output_batch extending 733\n",
      "output_batch extending 735\n",
      "output_batch extending 737\n",
      "output_batch extending 739\n",
      "output_batch extending 741\n",
      "output_batch extending 743\n",
      "output_batch extending 745\n",
      "output_batch extending 747\n",
      "output_batch extending 749\n",
      "output_batch extending 751\n",
      "output_batch extending 753\n",
      "output_batch extending 755\n",
      "output_batch extending 757\n",
      "output_batch extending 759\n",
      "output_batch extending 761\n",
      "output_batch extending 763\n",
      "output_batch extending 765\n",
      "output_batch extending 767\n",
      "output_batch extending 769\n",
      "output_batch extending 771\n",
      "output_batch extending 773\n",
      "output_batch extending 775\n",
      "output_batch extending 777\n",
      "output_batch extending 779\n",
      "output_batch extending 781\n",
      "output_batch extending 783\n",
      "output_batch extending 785\n",
      "output_batch extending 787\n",
      "output_batch extending 789\n",
      "output_batch extending 791\n",
      "output_batch extending 793\n",
      "output_batch extending 795\n",
      "output_batch extending 797\n",
      "output_batch extending 799\n",
      "output_batch extending 801\n",
      "output_batch extending 803\n",
      "output_batch extending 805\n",
      "output_batch extending 807\n",
      "output_batch extending 809\n",
      "output_batch extending 811\n",
      "output_batch extending 813\n",
      "output_batch extending 815\n",
      "output_batch extending 817\n",
      "output_batch extending 819\n",
      "output_batch extending 821\n",
      "output_batch extending 823\n",
      "output_batch extending 825\n",
      "output_batch extending 827\n",
      "output_batch extending 829\n",
      "output_batch extending 831\n",
      "output_batch extending 833\n",
      "output_batch extending 835\n",
      "output_batch extending 837\n",
      "output_batch extending 839\n",
      "output_batch extending 841\n",
      "output_batch extending 843\n"
     ]
    }
   ],
   "source": [
    "next(data_gen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(PULSE_AMOUNT, len(FEATURES))))\n",
    "model.add(Dense(2, activation='linear')) # set the number of output neurons to 2 and the activation function to linear\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_3' (type Sequential).\n    \n    Input 0 of layer \"lstm_3\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, None)\n    \n    Call arguments received by layer 'sequential_3' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, None), dtype=float64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train the model \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# with input sequence (num_samples, num_timesteps, num_features),\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# and the azimuth and zenith angle values for each sequence.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49mfit(data_gen, steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9ixb6olo.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_3' (type Sequential).\n    \n    Input 0 of layer \"lstm_3\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, None)\n    \n    Call arguments received by layer 'sequential_3' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, None), dtype=float64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model \n",
    "# with input sequence (num_samples, num_timesteps, num_features),\n",
    "# and the azimuth and zenith angle values for each sequence.\n",
    "model.fit(data_gen, steps_per_epoch=50, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(test_sequences, test_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_dist_score(az_true:float, zen_true:float, az_pred:float, zen_pred:float):\n",
    "    '''\n",
    "    calculate the MAE of the angular distance between two directions.\n",
    "    The two vectors are first converted to cartesian unit vectors,\n",
    "    and then their scalar product is computed, which is equal to\n",
    "    the cosine of the angle between the two vectors. The inverse \n",
    "    cosine (arccos) thereof is then the angle between the two input vectors\n",
    "    \n",
    "    The lower the angle, the more similar the two vectors are meaning the score is better.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    az_true : float (or array thereof)\n",
    "        true azimuth value(s) in radian\n",
    "    zen_true : float (or array thereof)\n",
    "        true zenith value(s) in radian\n",
    "    az_pred : float (or array thereof)\n",
    "        predicted azimuth value(s) in radian\n",
    "    zen_pred : float (or array thereof)\n",
    "        predicted zenith value(s) in radian\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    \n",
    "    dist : float\n",
    "        mean over the angular distance(s) in radian\n",
    "    '''\n",
    "    \n",
    "    if not (np.all(np.isfinite(az_true)) and\n",
    "            np.all(np.isfinite(zen_true)) and\n",
    "            np.all(np.isfinite(az_pred)) and\n",
    "            np.all(np.isfinite(zen_pred))):\n",
    "        raise ValueError(\"All arguments must be finite\")\n",
    "    \n",
    "    # pre-compute all sine and cosine values\n",
    "    sa1 = np.sin(az_true)\n",
    "    ca1 = np.cos(az_true)\n",
    "    sz1 = np.sin(zen_true)\n",
    "    cz1 = np.cos(zen_true)\n",
    "    \n",
    "    sa2 = np.sin(az_pred)\n",
    "    ca2 = np.cos(az_pred)\n",
    "    sz2 = np.sin(zen_pred)\n",
    "    cz2 = np.cos(zen_pred)\n",
    "    \n",
    "    # scalar product of the two Cartesian vectors (x = sz*ca, y = sz*sa, z = cz)\n",
    "    scalar_prod = sz1*sz2*(ca1*ca2 + sa1*sa2) + (cz1*cz2)\n",
    "    \n",
    "    # scalar product of two unit vectors is always between -1 and 1, this is against numerical instability\n",
    "    # that might otherwise occur from the finite precision of the sine and cosine functions\n",
    "    scalar_prod =  np.clip(scalar_prod, -1, 1)\n",
    "    \n",
    "    # convert back to an angle (in radian)\n",
    "    return np.average(np.abs(np.arccos(scalar_prod)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KAG_IC_NEU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad40088d582bffe2fc05846b5516a111df7b25e3d4e8e50a24f706fb2c5c2959"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
