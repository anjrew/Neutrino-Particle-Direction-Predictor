{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Neutrino Direction with an LSTM\n",
    "\n",
    "Using a Tensorflow LSTM layer using the event time steps to the input to predict the Neutrino Direction azimuth and zenith angle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import logging\n",
    "from sys import getsizeof\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.append('..')\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Typing imports\n",
    "from typing import List\n",
    "\n",
    "from scripts.utils import seed_it_all, convert_bytes_to_gmbkb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MODEL_TYPE='lstm' # Which model to use\n",
    "IS_TRAINING = True # Whether to train the model\n",
    "SEED=10\n",
    "\n",
    "TRY_TO_USE_GPU=True # Whether to try to use GPU\n",
    "\n",
    "LSTM_UNITS = 64\n",
    "EPOCHS=20\n",
    "STEPS_PER_EPOCH=50\n",
    "PULSE_AMOUNT = 120 # Amount of pulses to use for features\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "FEATURES = [ 'time', 'charge', 'auxiliary', 'x', 'y', 'z'] # Which features to use as the model input\n",
    "\n",
    "# Directories\n",
    "DATA_DIR = \"../data\"\n",
    "SET = 'train' if IS_TRAINING else 'test'\n",
    "\n",
    "# logging\n",
    "LOG_LEVEL = logging.INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "Num GPUs Available:  1\n",
      "CUDA version:  True\n",
      "cuDNN version:  True\n",
      "TensorFlow version:  2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:39:41.717520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-24 16:39:41.717634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.77GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2023-02-24 16:39:41.717755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-24 16:39:41.717844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-24 16:39:41.717896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-02-24 16:39:41.717919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-24 16:39:41.717924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-02-24 16:39:41.717927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-02-24 16:39:41.717992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-24 16:39:41.718094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-24 16:39:41.718156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 7460 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/aj/anaconda3/envs/KAG_IC_NEU:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "# packages in environment at /home/aj/anaconda3/envs/KAG_IC_NEU:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n"
     ]
    }
   ],
   "source": [
    "using_gpu = False\n",
    "\n",
    "if not TRY_TO_USE_GPU:\n",
    "  os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "else:\n",
    "  device_name = tf.test.gpu_device_name()\n",
    "  if device_name != '/device:GPU:0':\n",
    "    print('GPU device NOT found')\n",
    "  else:\n",
    "    using_gpu=True\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "    physical_devices = tf.config.list_physical_devices('GPU') \n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    print(\"CUDA version: \", tf.test.is_built_with_cuda())\n",
    "    print(\"cuDNN version: \", tf.test.is_built_with_gpu_support())\n",
    "    print(\"TensorFlow version: \", tf.__version__)\n",
    "    \n",
    "    !conda list cudatoolkit\n",
    "    !conda list cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "CUDA version:  True\n",
      "cuDNN version:  True\n",
      "TensorFlow version:  2.11.0\n",
      "/bin/bash: /home/aj/anaconda3/envs/KAG_IC_NEU/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "# packages in environment at /home/aj/anaconda3/envs/KAG_IC_NEU:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "cudatoolkit               11.2.2              hbe64b41_10    conda-forge\n",
      "/bin/bash: /home/aj/anaconda3/envs/KAG_IC_NEU/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "# packages in environment at /home/aj/anaconda3/envs/KAG_IC_NEU:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "cudnn                     8.1.0.77             h90431f1_0    conda-forge\n",
      "nvidia-cudnn              8.2.0.51                 pypi_0    pypi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 11:15:18.146375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-24 11:15:18.146865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-24 11:15:18.147250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-24 11:15:18.147889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-24 11:15:18.148378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-24 11:15:18.148818: I tensorflow/core/common_runtime/gpu/gpu"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_device.cc:1613] Created device /device:GPU:0 with 759 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(filename='artifacts/info.log', level=LOG_LEVEL, format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_it_all(SEED)\n",
    "# set the seed for the random number generator\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-256.25</td>\n",
       "      <td>-521.0</td>\n",
       "      <td>496.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_id       x      y      z\n",
       "0          0 -256.25 -521.0  496.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_dtypes = { 'x': 'float16', 'y': 'float16', 'z': 'float16' }\n",
    "sensor_geometry_df = pd.read_csv(f'{DATA_DIR}/sensor_geometry.csv', dtype=sensor_dtypes) # type: ignore\n",
    "sensor_geometry_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70.69 KB'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_bytes_to_gmbkb(getsizeof(sensor_geometry_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>first_pulse_index</th>\n",
       "      <th>last_pulse_index</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>zenith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>5.03125</td>\n",
       "      <td>2.087891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_id  event_id  first_pulse_index  last_pulse_index  azimuth    zenith\n",
       "0         1        24                  0                60  5.03125  2.087891"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "meta_dtypes = {'batch_id': 'int16', 'event_id': 'Int64', 'first_pulse_index': 'int32', 'last_pulse_index': 'int32', 'azimuth': 'float16', 'zenith': 'float16'}\n",
    "meta_df = pd.read_parquet(f'{DATA_DIR}/{SET}_meta.parquet').astype(meta_dtypes)\n",
    "meta_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.83 GB'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_bytes_to_gmbkb(getsizeof(meta_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_directory = f'{DATA_DIR}/{SET}'\n",
    "batch_file_paths = [f'{batch_directory}/{file}' for file in os.listdir(batch_directory) if os.path.isfile(os.path.join(batch_directory, file))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_file_paths = batch_file_paths[:-1]\n",
    "validation_batch_file_paths = batch_file_paths[-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.83 GB'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch_df= pd.read_parquet(batch_file_paths[1])\n",
    "convert_bytes_to_gmbkb(getsizeof(meta_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_input_observation(batch: pd.DataFrame, event_id: int, sequence_length: int, sensor_geometry: pd.DataFrame,) -> np.ndarray: \n",
    "    \"\"\"Gets a single event input observation for the model\n",
    "\n",
    "    Args:\n",
    "        batch (pd.DataFrame): The batch dataframe\n",
    "        event_id (int): The event id to find within the batch df\n",
    "        sequence_length (int): The length of the sequence to use\n",
    "        sensor_geometry (pd.DataFrame): The sensor geometry dataframe\n",
    "\n",
    "    Returns:\n",
    "        np.array: A single event input observation for the model\n",
    "    \"\"\"\n",
    "    # The event dataframe with a list of pulse readings\n",
    "    event_data = batch[batch['event_id'] == event_id]\n",
    "    \n",
    "    merged_df = pd.merge(event_data, sensor_geometry, on='sensor_id', how='left')\n",
    "    \n",
    "    # get the first N pulses with N being the sequence length\n",
    "    sequence = merged_df.head(sequence_length)[FEATURES]\n",
    "    n_missing = PULSE_AMOUNT - len(sequence)\n",
    "    if n_missing > 0:\n",
    "        df_missing = pd.DataFrame(0, index=np.arange(n_missing), columns=sequence.columns)\n",
    "        sequence = pd.concat([sequence, df_missing])\n",
    "        \n",
    "    return sequence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_data(batch: pd.DataFrame, event_id: int, sequence_length: int, sensor_geometry: pd.DataFrame, meta_data: pd.DataFrame):\n",
    "    \n",
    "    input_sequence = get_event_input_observation(batch, event_id, sequence_length, sensor_geometry)\n",
    "    \n",
    "    # get the target labels \n",
    "    target_labels = meta_data[meta_data['event_id'] == event_id][['azimuth', 'zenith']].values[0] \n",
    "    \n",
    "    # reshape the sequence and target labels to be fed into the model\n",
    "    return np.reshape(input_sequence, (1, sequence_length, len(FEATURES))), np.reshape(target_labels, (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def data_generator(\n",
    "    batch_paths: List[str],\n",
    "    sensor_geometry: pd.DataFrame,\n",
    "    meta_data: pd.DataFrame,\n",
    "    sequence_length: int,\n",
    "    batch_size: int = BATCH_SIZE\n",
    "):\n",
    "    \"\"\"Emits a single event training example to be called by the model.fit_generator() method.\n",
    "\n",
    "    Args:\n",
    "        batch_paths (List[str]): A list of paths to the batch files\n",
    "        sensor_geometry_df (pd.DataFrame): The sensor geometry dataframe\n",
    "        meta_df (pd.DataFrame): The dataframe containing the meta data\n",
    "        sequence_length (int): The length of the pulse sequence to use for training\n",
    "\n",
    "    Yields:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    batch_dtypes = {'event_id': 'int32', 'sensor_id': 'int16',\n",
    "                    'time': 'int32', 'charge': 'float16', 'auxiliary': 'int8'}\n",
    "\n",
    "    for batch_path in batch_paths:\n",
    "\n",
    "        batch = pd.read_parquet(batch_path).reset_index().astype(batch_dtypes)\n",
    "\n",
    "        output_batch_x = None\n",
    "        output_batch_y = None\n",
    "\n",
    "        for event_id in batch['event_id'].unique():\n",
    "\n",
    "            x_batch, y_batch = get_event_data(\n",
    "                batch, event_id, sequence_length, sensor_geometry, meta_data)\n",
    "\n",
    "            x_tensor = tf.constant(x_batch)\n",
    "            y_tensor = tf.constant(y_batch)\n",
    "\n",
    "            if output_batch_x is None and output_batch_y is None:\n",
    "                output_batch_x = x_tensor\n",
    "                output_batch_y = y_tensor\n",
    "                logging.debug('Output_batch initializing')\n",
    "\n",
    "            else:\n",
    "                output_batch_x = tf.concat([output_batch_x, x_tensor], axis=0)\n",
    "                output_batch_y = tf.concat([output_batch_y, y_tensor], axis=0)\n",
    "\n",
    "                logging.debug('Output_batch extending: %s',\n",
    "                              len(output_batch_x))\n",
    "\n",
    "            if len(output_batch_x) == batch_size:\n",
    "                output = output_batch_x[:], output_batch_y[:]\n",
    "                output_batch_x = None\n",
    "                output_batch_y = None\n",
    "                yield output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a generator object\n",
    "train_data_gen = data_generator(training_batch_file_paths, sensor_geometry_df, meta_df, sequence_length=PULSE_AMOUNT, batch_size=BATCH_SIZE)\n",
    "val_data_gen = data_generator(validation_batch_file_paths, sensor_geometry_df, meta_df, sequence_length=PULSE_AMOUNT, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'adam' from 'keras.optimizers' (/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.9/site-packages/keras/optimizers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m LSTM, Dense, CuDNNLSTM\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m adam\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'adam' from 'keras.optimizers' (/home/aj/anaconda3/envs/KAG_IC_NEU/lib/python3.9/site-packages/keras/optimizers.py)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, CuDNNLSTM\n",
    "# from keras.optimizers import adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = f'{MODEL_TYPE}_{datetime.now().strftime(\"%d%m%Y%H%M%S\")}'.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "\n",
    "    ModelCheckpoint(\n",
    "        filepath=f\"checkpoints/{RUN_ID}/{'epoch:02d'}\",\n",
    "        save_weights_only=True,\n",
    "        save_freq='epoch'),\n",
    "\n",
    "    ModelCheckpoint(f'checkpoints/{RUN_ID}/best_model_weights.h5',\n",
    "                    save_best_only=True,\n",
    "                    save_weights_only=True,\n",
    "                    monitor='val_loss',\n",
    "                    mode='min',\n",
    "                    verbose=1),\n",
    "\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10\n",
    "    ),\n",
    "\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        min_lr=1e-8 # type: ignore\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CuDNNLSTM\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "lstm_type = CuDNNLSTM if using_gpu else LSTM\n",
    "# lstm_type = LSTM\n",
    "\n",
    "print('Using', lstm_type.__name__)\n",
    "\n",
    "# optimizer = Adam(learning_rate=LEARNING_RATE), \n",
    "\n",
    "# model.add(LSTM(LSTM_UNITS,input_shape=(PULSE_AMOUNT, len(FEATURES))))\n",
    "model.add(lstm_type(LSTM_UNITS,input_shape=(PULSE_AMOUNT, len(FEATURES))))\n",
    "model.add(Dense(2, activation='linear')) # set the number of output neurons to 2 and the activation function to linear\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='mean_squared_error', \n",
    "    # optimizer=optimizer, \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "The amount of training examples that are in an epoch when using is not the entire dataset like in normal problems. \n",
    "Because the total number of training examples are not known the amount of training examples in an epoch is calculated as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.tensorflow.autolog(every_n_iter=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial lstm_24022023164855: LSTM model using 120 sequence length with 64\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:51:01.268818: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-02-24 16:51:02.128528: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\n",
      "2023-02-24 16:51:02.755477: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/32 [..............................] - ETA: 2:44 - loss: 9.0020 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 16:51:03.195265: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-02-24 16:51:03.195298: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/32 [=========================>....] - ETA: 16s - loss: 6.9872 - accuracy: 0.7185"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m history\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     15\u001b[0m         train_data_gen,\n\u001b[1;32m     16\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49mBATCH_SIZE, \n\u001b[1;32m     17\u001b[0m         epochs\u001b[39m=\u001b[39;49mEPOCHS, \n\u001b[1;32m     18\u001b[0m         \n\u001b[1;32m     19\u001b[0m         batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[1;32m     20\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m     21\u001b[0m         \u001b[39m# use_multiprocessing=True,\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m         \u001b[39m# workers=4,\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m         \n\u001b[1;32m     24\u001b[0m         \u001b[39m# Validation Settings\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m         validation_data\u001b[39m=\u001b[39;49mval_data_gen, \n\u001b[1;32m     26\u001b[0m         validation_batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[1;32m     27\u001b[0m         validation_steps\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, \n\u001b[1;32m     28\u001b[0m         validation_freq\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     29\u001b[0m         \n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m     mlflow\u001b[39m.\u001b[39mend_run()\n\u001b[1;32m     32\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/KAG_IC_NEU/lib/python3.9/site-packages/keras/engine/training.py:1158\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1152\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1153\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1154\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1155\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1156\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1157\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1158\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1159\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1160\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/KAG_IC_NEU/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/KAG_IC_NEU/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/KAG_IC_NEU/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   3021\u001b[0m   (graph_function,\n\u001b[1;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/KAG_IC_NEU/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m     args,\n\u001b[1;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1965\u001b[0m     executing_eagerly)\n\u001b[1;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/KAG_IC_NEU/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/KAG_IC_NEU/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "description = f'LSTM model using {PULSE_AMOUNT} sequence length with {LSTM_UNITS}'\n",
    "print(f'--- Starting trial {RUN_ID}: {description}')\n",
    "\n",
    "mlflow.set_experiment('LSTM')\n",
    "mlflow.start_run(run_name=RUN_ID, description=description)\n",
    "mlflow.log_param('batch_size', BATCH_SIZE)\n",
    "mlflow.log_param('sequence_length', PULSE_AMOUNT)\n",
    "mlflow.log_param('lstm_units', LSTM_UNITS)\n",
    "\n",
    "# mlflow.log_param('learning_rate', LEARNING_RATE)\n",
    "# mlflow.log_param('epochs')\n",
    "history=None\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_data_gen,\n",
    "        steps_per_epoch=BATCH_SIZE, \n",
    "        epochs=EPOCHS, \n",
    "        \n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        # use_multiprocessing=True,\n",
    "        # workers=4,\n",
    "        \n",
    "        # Validation Settings\n",
    "        validation_data=val_data_gen, \n",
    "        validation_batch_size=BATCH_SIZE,\n",
    "        validation_steps=3, \n",
    "        validation_freq=1,\n",
    "        \n",
    "    )\n",
    "    mlflow.end_run()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    mlflow.end_run(status='FAILED')\n",
    "    raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "# loss = model.evaluate(test_sequences, test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_dist_score(az_true:float, zen_true:float, az_pred:float, zen_pred:float):\n",
    "    '''\n",
    "    calculate the MAE of the angular distance between two directions.\n",
    "    The two vectors are first converted to cartesian unit vectors,\n",
    "    and then their scalar product is computed, which is equal to\n",
    "    the cosine of the angle between the two vectors. The inverse \n",
    "    cosine (arccos) thereof is then the angle between the two input vectors\n",
    "    \n",
    "    The lower the angle, the more similar the two vectors are meaning the score is better.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    az_true : float (or array thereof)\n",
    "        true azimuth value(s) in radian\n",
    "    zen_true : float (or array thereof)\n",
    "        true zenith value(s) in radian\n",
    "    az_pred : float (or array thereof)\n",
    "        predicted azimuth value(s) in radian\n",
    "    zen_pred : float (or array thereof)\n",
    "        predicted zenith value(s) in radian\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    \n",
    "    dist : float\n",
    "        mean over the angular distance(s) in radian\n",
    "    '''\n",
    "    \n",
    "    if not (np.all(np.isfinite(az_true)) and\n",
    "            np.all(np.isfinite(zen_true)) and\n",
    "            np.all(np.isfinite(az_pred)) and\n",
    "            np.all(np.isfinite(zen_pred))):\n",
    "        raise ValueError(\"All arguments must be finite\")\n",
    "    \n",
    "    # pre-compute all sine and cosine values\n",
    "    sa1 = np.sin(az_true)\n",
    "    ca1 = np.cos(az_true)\n",
    "    sz1 = np.sin(zen_true)\n",
    "    cz1 = np.cos(zen_true)\n",
    "    \n",
    "    sa2 = np.sin(az_pred)\n",
    "    ca2 = np.cos(az_pred)\n",
    "    sz2 = np.sin(zen_pred)\n",
    "    cz2 = np.cos(zen_pred)\n",
    "    \n",
    "    # scalar product of the two Cartesian vectors (x = sz*ca, y = sz*sa, z = cz)\n",
    "    scalar_prod = sz1*sz2*(ca1*ca2 + sa1*sa2) + (cz1*cz2)\n",
    "    \n",
    "    # scalar product of two unit vectors is always between -1 and 1, this is against numerical instability\n",
    "    # that might otherwise occur from the finite precision of the sine and cosine functions\n",
    "    scalar_prod =  np.clip(scalar_prod, -1, 1)\n",
    "    \n",
    "    # convert back to an angle (in radian)\n",
    "    return np.average(np.abs(np.arccos(scalar_prod)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KAG_IC_NEU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad40088d582bffe2fc05846b5516a111df7b25e3d4e8e50a24f706fb2c5c2959"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
