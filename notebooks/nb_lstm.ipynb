{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Neutrino Direction with an LSTM\n",
    "\n",
    "Using a Tensorflow LSTM layer using the event time steps to the input to predict the Neutrino Direction azimuth and zenith angle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Typing imports\n",
    "from typing import List, Tuple\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH = 1 # What batch file to use?\n",
    "EXCLUDE_AUXILIARY = True # Whether to exclude auxiliary pulses\n",
    "IS_TRAINING = True # Whether to train the model\n",
    "# If either the event or time limit is reached the process will exit\n",
    "EVENT_LIMIT = 3000\n",
    "TIME_LIMIT_HOURS = 1\n",
    "PULSE_AMOUNT = 200 # Amount of pulses to use for features\n",
    "FEATURES= set(('charge', 'x', 'y', 'z')) # Which features to use for training\n",
    "DATA_TYPES={'A': 'int32', 'B': 'category', 'C': 'float32'}\n",
    "\n",
    "# Directories\n",
    "DATA_DIR = \"data\"\n",
    "SET = 'train' if IS_TRAINING else 'test'\n",
    "\n",
    "# logging\n",
    "LOG_LEVEL = logging.INFO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(filename='artifacts/info.log', level=LOG_LEVEL, format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_it_all(seed=7):\n",
    "    \"\"\" Attempt to be Reproducible \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "seed_it_all(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        logging.info(f'Optimizing col {col}')\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    logging.info('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    logging.info('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def import_data(file: str):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    function_name = f\"read_{file.split('.')[-1]}\"\n",
    "    function = getattr(pd, function_name)\n",
    "    df = function(file)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "def get_event_df(batch_df: dd.DataFrame, sensor_geometry: pd.DataFrame, event_id: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get a DataFrame for a specific event.\n",
    "\n",
    "    Parameters:\n",
    "    train_batch_df (pandas.DataFrame): The batch DataFrame.\n",
    "    sensor_geometry (pandas.DataFrame): The sensor geometry DataFrame.\n",
    "    event_id (str): The event identifier.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing data for the specified event.\n",
    "    \"\"\"\n",
    "    if EXCLUDE_AUXILIARY:\n",
    "        batch_df = batch_df[~batch_df['auxiliary']].drop(columns=['auxiliary'])\n",
    "    \n",
    "    event_df = batch_df[batch_df['event_id'] == event_id].compute()\n",
    "        \n",
    "    event_df = pd.merge(\n",
    "        left=event_df,\n",
    "        right=sensor_geometry,\n",
    "        how='inner',\n",
    "        on='sensor_id'\n",
    "    ),\n",
    "    \n",
    "    ## Drop columns that are not needed for prediction\n",
    "    return event_df.drop(columns=['event_id', 'sensor_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_vector(batch: dd.DataFrame, event_id: int) -> pd.DataFrame:\n",
    "    \"\"\"Changes the rows of a dataframe to columns\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe to be converted that currently has observations in rows\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A single observation in columns\n",
    "    \"\"\"\n",
    "    df = make_input_vector_shape(df)\n",
    "    df = df.stack().reset_index()\n",
    "    df['features'] = df['level_0'].astype(str) + '_' + df['level_1']\n",
    "    df = df.drop(columns=['level_0','level_1']).set_index('features')\n",
    "    df = df.T.set_index(pd.Index([event_id]))\n",
    "    df.index.name = 'event_id'\n",
    "    \n",
    "    return pd.merge(\n",
    "        df, \n",
    "        meta_dfd[meta_dfd['event_id']== event_id].compute()[[ 'event_id','azimuth','zenith' ]], \n",
    "        on='event_id', \n",
    "        how='inner'\n",
    "    ).set_index('event_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-256.14</td>\n",
       "      <td>-521.08</td>\n",
       "      <td>496.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_id       x       y       z\n",
       "0          0 -256.14 -521.08  496.03"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_geometry_dfd = dd.read_csv(f'{DATA_DIR}/sensor_geometry.csv',\n",
    "    blocksize=1024 ** 3 # 1GB\n",
    ")\n",
    "sensor_geometry_dfd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>first_pulse_index</th>\n",
       "      <th>last_pulse_index</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>zenith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>5.029555</td>\n",
       "      <td>2.087498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_id  event_id  first_pulse_index  last_pulse_index   azimuth    zenith\n",
       "0         1        24                  0                60  5.029555  2.087498"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dfd = dd.read_parquet(f'{DATA_DIR}/{SET}_meta.parquet', \n",
    "    n_partitions= 2,                                      \n",
    "    blocksize=1024 ** 3 # 1GB\n",
    ")\n",
    "meta_dfd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>time</th>\n",
       "      <th>charge</th>\n",
       "      <th>auxiliary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>3918</td>\n",
       "      <td>5928</td>\n",
       "      <td>1.325</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id  sensor_id  time  charge  auxiliary\n",
       "0        24       3918  5928   1.325       True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch_dfd = dd.read_parquet(f'{DATA_DIR}/{SET}/batch_1.parquet', \n",
    "     n_partitions= 2,                                      \n",
    "    blocksize=1024 ** 3 # 1GB\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "test_batch_dfd.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>time</th>\n",
       "      <th>charge</th>\n",
       "      <th>auxiliary</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>3918</td>\n",
       "      <td>5928</td>\n",
       "      <td>1.325</td>\n",
       "      <td>True</td>\n",
       "      <td>303.41</td>\n",
       "      <td>335.64</td>\n",
       "      <td>206.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2743</td>\n",
       "      <td>3918</td>\n",
       "      <td>10813</td>\n",
       "      <td>0.975</td>\n",
       "      <td>True</td>\n",
       "      <td>303.41</td>\n",
       "      <td>335.64</td>\n",
       "      <td>206.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3007</td>\n",
       "      <td>3918</td>\n",
       "      <td>10290</td>\n",
       "      <td>0.925</td>\n",
       "      <td>False</td>\n",
       "      <td>303.41</td>\n",
       "      <td>335.64</td>\n",
       "      <td>206.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id  sensor_id   time  charge  auxiliary       x       y       z\n",
       "0        24       3918   5928   1.325       True  303.41  335.64  206.58\n",
       "1      2743       3918  10813   0.975       True  303.41  335.64  206.58\n",
       "2      3007       3918  10290   0.925      False  303.41  335.64  206.58"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dfd = dd.merge(test_batch_dfd, sensor_geometry_dfd, on='sensor_id', how='inner')\n",
    "\n",
    "merged_dfd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>time</th>\n",
       "      <th>charge</th>\n",
       "      <th>auxiliary</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>3918</td>\n",
       "      <td>5928</td>\n",
       "      <td>1.325</td>\n",
       "      <td>True</td>\n",
       "      <td>303.41</td>\n",
       "      <td>335.64</td>\n",
       "      <td>206.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>24</td>\n",
       "      <td>4157</td>\n",
       "      <td>6115</td>\n",
       "      <td>1.175</td>\n",
       "      <td>True</td>\n",
       "      <td>-145.45</td>\n",
       "      <td>374.24</td>\n",
       "      <td>212.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10172</th>\n",
       "      <td>24</td>\n",
       "      <td>3520</td>\n",
       "      <td>6492</td>\n",
       "      <td>0.925</td>\n",
       "      <td>True</td>\n",
       "      <td>505.27</td>\n",
       "      <td>257.88</td>\n",
       "      <td>-174.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       event_id  sensor_id  time  charge  auxiliary       x       y       z\n",
       "0            24       3918  5928   1.325       True  303.41  335.64  206.58\n",
       "5364         24       4157  6115   1.175       True -145.45  374.24  212.73\n",
       "10172        24       3520  6492   0.925       True  505.27  257.88 -174.60"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dfd = merged_dfd.sort_values(by=['event_id', 'time'])\n",
    "sorted_dfd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(columns=[])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 20:46:32.378313: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-17 20:46:33.260423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-17 20:46:33.260436: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-17 20:46:34.319346: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-17 20:46:34.319419: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-17 20:46:34.319429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(PULSE_AMOUNT, len(FEATURES))))\n",
    "model.add(Dense(2, activation='linear')) # set the number of output neurons to 2 and the activation function to linear\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model \n",
    "# with input sequence (num_samples, num_timesteps, num_features),\n",
    "# and the azimuth and zenith angle values for each sequence.\n",
    "model.fit(input_sequences, output_values, batch_size=32, epochs=100)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(test_sequences, test_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_dist_score(az_true:float, zen_true:float, az_pred:float, zen_pred:float):\n",
    "    '''\n",
    "    calculate the MAE of the angular distance between two directions.\n",
    "    The two vectors are first converted to cartesian unit vectors,\n",
    "    and then their scalar product is computed, which is equal to\n",
    "    the cosine of the angle between the two vectors. The inverse \n",
    "    cosine (arccos) thereof is then the angle between the two input vectors\n",
    "    \n",
    "    The lower the angle, the more similar the two vectors are meaning the score is better.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    az_true : float (or array thereof)\n",
    "        true azimuth value(s) in radian\n",
    "    zen_true : float (or array thereof)\n",
    "        true zenith value(s) in radian\n",
    "    az_pred : float (or array thereof)\n",
    "        predicted azimuth value(s) in radian\n",
    "    zen_pred : float (or array thereof)\n",
    "        predicted zenith value(s) in radian\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    \n",
    "    dist : float\n",
    "        mean over the angular distance(s) in radian\n",
    "    '''\n",
    "    \n",
    "    if not (np.all(np.isfinite(az_true)) and\n",
    "            np.all(np.isfinite(zen_true)) and\n",
    "            np.all(np.isfinite(az_pred)) and\n",
    "            np.all(np.isfinite(zen_pred))):\n",
    "        raise ValueError(\"All arguments must be finite\")\n",
    "    \n",
    "    # pre-compute all sine and cosine values\n",
    "    sa1 = np.sin(az_true)\n",
    "    ca1 = np.cos(az_true)\n",
    "    sz1 = np.sin(zen_true)\n",
    "    cz1 = np.cos(zen_true)\n",
    "    \n",
    "    sa2 = np.sin(az_pred)\n",
    "    ca2 = np.cos(az_pred)\n",
    "    sz2 = np.sin(zen_pred)\n",
    "    cz2 = np.cos(zen_pred)\n",
    "    \n",
    "    # scalar product of the two Cartesian vectors (x = sz*ca, y = sz*sa, z = cz)\n",
    "    scalar_prod = sz1*sz2*(ca1*ca2 + sa1*sa2) + (cz1*cz2)\n",
    "    \n",
    "    # scalar product of two unit vectors is always between -1 and 1, this is against numerical instability\n",
    "    # that might otherwise occur from the finite precision of the sine and cosine functions\n",
    "    scalar_prod =  np.clip(scalar_prod, -1, 1)\n",
    "    \n",
    "    # convert back to an angle (in radian)\n",
    "    return np.average(np.abs(np.arccos(scalar_prod)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KAG_IC_NEU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad40088d582bffe2fc05846b5516a111df7b25e3d4e8e50a24f706fb2c5c2959"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
